{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_Diretory=\"./Datasets/ml-100k\"\n",
    "dataset_with_credit=\"./Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get the Genres from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children's</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unknown  0\n",
       "0      Action  1\n",
       "1   Adventure  2\n",
       "2   Animation  3\n",
       "3  Children's  4\n",
       "4      Comedy  5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genres\n",
    "genre_df = pd.read_csv(f'{dataset_Diretory}/u.genre', sep='|', encoding='latin-1')\n",
    "genre_columns = [\"unknown\"] + list(genre_df[genre_df.columns[0]].values)\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>Aleksei Ananishnov</th>\n",
       "      <th>Gudrun Geyer</th>\n",
       "      <th>Asia Argento</th>\n",
       "      <th>Jonathan Rhys Meyers</th>\n",
       "      <th>Julie T. Wallace</th>\n",
       "      <th>Werner Herzog</th>\n",
       "      <th>Vittorio Mezzogiorno</th>\n",
       "      <th>Stefan Glowacz</th>\n",
       "      <th>Mathilda May</th>\n",
       "      <th>Gunilla Karlzen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title release_date  video_release_date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            imdb_url  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's  ...  Aleksei Ananishnov  Gudrun Geyer  \\\n",
       "0          0          1           1  ...                   0             0   \n",
       "1          1          0           0  ...                   0             0   \n",
       "2          0          0           0  ...                   0             0   \n",
       "3          0          0           0  ...                   0             0   \n",
       "4          0          0           0  ...                   0             0   \n",
       "\n",
       "   Asia Argento  Jonathan Rhys Meyers  Julie T. Wallace  Werner Herzog  \\\n",
       "0             0                     0                 0              0   \n",
       "1             0                     0                 0              0   \n",
       "2             0                     0                 0              0   \n",
       "3             0                     0                 0              0   \n",
       "4             0                     0                 0              0   \n",
       "\n",
       "   Vittorio Mezzogiorno  Stefan Glowacz  Mathilda May  Gunilla Karlzen  \n",
       "0                     0               0             0                0  \n",
       "1                     0               0             0                0  \n",
       "2                     0               0             0                0  \n",
       "3                     0               0             0                0  \n",
       "4                     0               0             0                0  \n",
       "\n",
       "[5 rows x 6216 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movie\n",
    "movie_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies_df = pd.read_csv(f'{dataset_with_credit}/movies_with_credits.csv', sep=',',\n",
    "                     encoding='latin-1')\n",
    "movie_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "# movies_df = pd.read_csv(f'{dataset_Diretory}/u.item', sep='|', names=movie_columns+genre_columns,\n",
    "#                      encoding='latin-1')\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ratings\n",
    "ratings_columns = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_df = pd.read_csv(f'{dataset_Diretory}/u.data', sep='\\t', names=ratings_columns)\n",
    "ratings_df.drop( \"unix_timestamp\", inplace = True, axis = 1 ) \n",
    "ratings_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove test data from ratings dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_11416\\1229437901.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_ratings=ratings_df.groupby('user_id', group_keys=False).apply(lambda x: x.sample(n=2, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Group by user_id and take 2 random samples per user\n",
    "test_ratings=ratings_df.groupby('user_id', group_keys=False).apply(lambda x: x.sample(n=2, random_state=42))\n",
    "\n",
    "# Drop those sampled rows from the original dataframe\n",
    "remaining_df = ratings_df.drop(test_ratings.index)\n",
    "\n",
    "# Copy the dataframe into ratings_df\n",
    "ratings_df=remaining_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.content-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making user profiles \n",
    "At this stage we are making the profiles to understand user's taste in movies.\n",
    "In order to do that we are multiplying the movie features with the rating user has provided and \n",
    "summing up all the features for each user to get a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.54 GiB for an array with shape (6211, 98114) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m genre_and_artists_cols \u001b[38;5;241m=\u001b[39m movies_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m5\u001b[39m:]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Multiply each genre column by the 'rating' to get weighted genres\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m merged_df[genre_and_artists_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenre_and_artists_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 3: Group by 'user_id' and sum the genre columns\u001b[39;00m\n\u001b[0;32m     11\u001b[0m user_genre_scores \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[genre_and_artists_cols]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:8383\u001b[0m, in \u001b[0;36mDataFrame.mul\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   8379\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(ops\u001b[38;5;241m.\u001b[39mmake_flex_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   8380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmul\u001b[39m(\n\u001b[0;32m   8381\u001b[0m     \u001b[38;5;28mself\u001b[39m, other, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   8382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 8383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flex_arith_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[0;32m   8385\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:8269\u001b[0m, in \u001b[0;36mDataFrame._flex_arith_method\u001b[1;34m(self, other, op, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   8266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   8267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, DataFrame):\n\u001b[0;32m   8268\u001b[0m         \u001b[38;5;66;03m# Another DataFrame\u001b[39;00m\n\u001b[1;32m-> 8269\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8271\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series):\n\u001b[0;32m   8272\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:8011\u001b[0m, in \u001b[0;36mDataFrame._combine_frame\u001b[1;34m(self, other, func, fill_value)\u001b[0m\n\u001b[0;32m   8008\u001b[0m         left, right \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mfill_binop(left, right, fill_value)\n\u001b[0;32m   8009\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(left, right)\n\u001b[1;32m-> 8011\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_arith_op\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_data\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:7956\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7950\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m   7951\u001b[0m     \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7952\u001b[0m     \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7953\u001b[0m     \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7954\u001b[0m \n\u001b[0;32m   7955\u001b[0m     \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[1;32m-> 7956\u001b[0m     bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7957\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   7958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7959\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   7960\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   7961\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   7963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7964\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[38;5;241m=\u001b[39mbm\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   7968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, Series) \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   7969\u001b[0m     \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1511\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperate_blockwise\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: BlockManager, array_op) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockManager:\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;124;03m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\ops.py:65\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     63\u001b[0m res_blks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[38;5;129;01min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 65\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43marray_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m         left_ea\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_ea\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(res_values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     71\u001b[0m     ):\n\u001b[0;32m     72\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.54 GiB for an array with shape (6211, 98114) and data type int64"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge the ratings and movies dataframes on 'movie_id'\n",
    "merged_df = pd.merge(ratings_df, movies_df, on='movie_id')\n",
    "\n",
    "# Step 2: Identify the genre & artists columns (columns from index 5 onwards in movies_df)\n",
    "genre_and_artists_cols = movies_df.columns[5:]\n",
    "\n",
    "# Multiply each genre column by the 'rating' to get weighted genres\n",
    "merged_df[genre_and_artists_cols] = merged_df[genre_and_artists_cols].mul(merged_df['rating'], axis=0)\n",
    "\n",
    "# Step 3: Group by 'user_id' and sum the genre columns\n",
    "user_genre_scores = merged_df.groupby('user_id')[genre_and_artists_cols].sum().reset_index()\n",
    "\n",
    "# Resulting dataset\n",
    "user_genre_scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data \n",
    "from os import system\n",
    "import warnings\n",
    "\n",
    "\n",
    "def normalize_rows_vectorized(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_normalized = df.copy()\n",
    "    numeric_cols = df_normalized.columns[1:]\n",
    "    df_normalized[numeric_cols] = df_normalized[numeric_cols].apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "\n",
    "    # Normalize columns 1–19\n",
    "    part1 = df_normalized.iloc[:, 1:20]\n",
    "    max1 = part1.max(axis=1).replace(0, np.nan)\n",
    "    df_normalized.iloc[:, 1:20] = part1.div(max1, axis=0)\n",
    "\n",
    "    # Normalize columns 20–end\n",
    "    part2 = df_normalized.iloc[:, 20:]\n",
    "    if not part2.empty:\n",
    "        max2 = part2.max(axis=1).replace(0, np.nan)\n",
    "        df_normalized.iloc[:, 20:] = part2.div(max2, axis=0)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "user_genre_scores = normalize_rows_vectorized(user_genre_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_genre_scores.to_csv(\"user_genre_scores\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated Movies: 270\n",
      "Unrated Movies: 1412\n"
     ]
    }
   ],
   "source": [
    "def get_unrated_movies(user_id, movies_df, ratings_df):\n",
    "    \n",
    "    # Get all unique movie IDs from the movies dataset\n",
    "    all_movies = movies_df['movie_id'].unique()\n",
    "    \n",
    "    # Get movies rated by the specific user\n",
    "    user_rated = ratings_df.loc[ratings_df['user_id'] == user_id, 'movie_id'].unique()\n",
    "    \n",
    "    # Find movies not rated by the user using set difference\n",
    "    unrated_movies = np.setdiff1d(all_movies, user_rated)\n",
    "    \n",
    "    return unrated_movies\n",
    "\n",
    "# Example: Get movies not rated by user_id = 1\n",
    "unrated_movies = get_unrated_movies(user_id=1, movies_df=movies_df, ratings_df=ratings_df)\n",
    "print(\"Rated Movies:\",len(movies_df)-len(unrated_movies))\n",
    "print(\"Unrated Movies:\", len(unrated_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_mov=movies_df.drop([\"video_release_date\",\"release_date\",\"imdb_url\",\"release_date\",\"movie_id\",\"title\"],axis=1,inplace=False)\n",
    "mov_matrix=mod_mov.values\n",
    "\n",
    "mod_user=user_genre_scores.drop([\"user_id\"],axis=1,inplace=False)\n",
    "user_matrix=mod_user.values\n",
    "\n",
    "score = np.dot(mov_matrix[5], user_matrix[1])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing to come up with top 10 recommendation for a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n_content(user_id, mov_matrix, user_matrix, movies_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommend top-N movies for a given user based on dot product scores.\n",
    "    \n",
    "    Parameters:\n",
    "        user_id (int): The target user index.\n",
    "        mov_matrix (np.ndarray): Movie feature matrix (e.g., item profiles).\n",
    "        user_matrix (np.ndarray): User-item rating matrix.\n",
    "        movies_df (DataFrame): Original movies DataFrame with metadata.\n",
    "        top_n (int): Number of recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Top-N recommended movies with prediction scores.\n",
    "    \"\"\"\n",
    "    user_id = user_id - 1\n",
    "    # Compute scores for all movies for the target user\n",
    "    scores = np.dot(mov_matrix, user_matrix[user_id])\n",
    "    \n",
    "    # Get indices of top-N scores\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "    top_scores = scores[top_indices]\n",
    "    \n",
    "    # Get corresponding movie IDs from movies_df\n",
    "    top_movie_ids = movies_df.iloc[top_indices]['movie_id'].values\n",
    "\n",
    "    # Return as list of (movie_id, prediction_score)\n",
    "    return list(zip(top_movie_ids, top_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(172, 5.630352860568688),\n",
       " (181, 4.630352860568688),\n",
       " (50, 4.458924289140117),\n",
       " (187, 4.072285029119561),\n",
       " (227, 3.8591983556012335),\n",
       " (228, 3.8591983556012335),\n",
       " (4, 3.776293251113395),\n",
       " (245, 3.704145255224391),\n",
       " (127, 3.6437136005481325),\n",
       " (17, 3.610208975676602)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top_n_content(\n",
    "    user_id=1,\n",
    "    mov_matrix=mov_matrix,         # NumPy array\n",
    "    user_matrix=user_matrix,       # NumPy array\n",
    "    movies_df=movies_df,           # DataFrame with movie metadata\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Item-Item Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make items_profile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix where each row represents a movie in terms of users ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix:\n",
      "user_id   1    2    3    4    5    6    7    8    9    10   ...  934  935  \\\n",
      "movie_id                                                    ...             \n",
      "1         5.0  4.0  NaN  NaN  4.0  4.0  NaN  NaN  NaN  4.0  ...  2.0  3.0   \n",
      "2         3.0  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  NaN  ...  4.0  NaN   \n",
      "3         4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "4         3.0  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  4.0  ...  5.0  NaN   \n",
      "5         3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "1678      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "1679      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "1680      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "1681      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "1682      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
      "\n",
      "user_id   936  937  938  939  940  941  942  943  \n",
      "movie_id                                          \n",
      "1         4.0  NaN  4.0  NaN  NaN  5.0  NaN  NaN  \n",
      "2         NaN  NaN  NaN  NaN  NaN  NaN  NaN  5.0  \n",
      "3         4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4         NaN  NaN  NaN  NaN  2.0  NaN  NaN  NaN  \n",
      "5         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "1678      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1679      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1680      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1681      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1682      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[1681 rows x 943 columns]\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix = ratings_df.pivot(index='movie_id', columns='user_id', values='rating')\n",
    "print(\"User-Item Matrix:\")\n",
    "print(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "1       5.0\n",
       "2       3.0\n",
       "3       4.0\n",
       "4       3.0\n",
       "5       3.0\n",
       "       ... \n",
       "1678    NaN\n",
       "1679    NaN\n",
       "1680    NaN\n",
       "1681    NaN\n",
       "1682    NaN\n",
       "Name: 1, Length: 1681, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to call a movie use .loc\n",
    "user_item_matrix.loc[1]\n",
    "\n",
    "#to call a user use \n",
    "user_item_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the similarity between two movies, we will use cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Handle NaNs by treating them as zeros or ignoring them\n",
    "    mask = ~np.isnan(vec1) & ~np.isnan(vec2)\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0  # no overlap in ratings\n",
    "    \n",
    "    v1 = vec1[mask]\n",
    "    v2 = vec2[mask]\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denominator = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488806385308644"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(user_item_matrix.loc[1].values, user_item_matrix.loc[2].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the similarity  between each movie and every other movie, the similarity Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4         5         6         7     \\\n",
      "1     1.000000  0.948881  0.915048  0.942102  0.960450  0.955119  0.950152   \n",
      "2     0.948881  1.000000  0.911985  0.939195  0.942688  0.955090  0.943322   \n",
      "3     0.915048  0.911985  1.000000  0.898737  0.942472  0.968364  0.920467   \n",
      "4     0.942102  0.939195  0.898737  1.000000  0.891994  0.919037  0.947734   \n",
      "5     0.960450  0.942688  0.942472  0.891994  1.000000  0.996241  0.935982   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1678  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1679  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1680  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1681  1.000000  1.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
      "1682  1.000000  1.000000  1.000000  1.000000  1.000000  0.000000  1.000000   \n",
      "\n",
      "          8         9         10    ...  1673  1674  1675  1676  1677  1678  \\\n",
      "1     0.960134  0.937197  0.947020  ...   1.0   0.0   0.0   0.0   1.0   0.0   \n",
      "2     0.952186  0.914693  0.943967  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3     0.880473  0.905344  0.926942  ...   0.0   0.0   0.0   0.0   1.0   0.0   \n",
      "4     0.953031  0.949449  0.958274  ...   0.0   0.0   1.0   1.0   1.0   0.0   \n",
      "5     0.945235  0.934037  0.904194  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "...        ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
      "1678  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   1.0   \n",
      "1679  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   1.0   \n",
      "1680  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   1.0   \n",
      "1681  1.000000  1.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1682  0.000000  1.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "      1679  1680  1681  1682  \n",
      "1      0.0   0.0   1.0   1.0  \n",
      "2      0.0   0.0   1.0   1.0  \n",
      "3      0.0   0.0   0.0   1.0  \n",
      "4      0.0   0.0   1.0   1.0  \n",
      "5      0.0   0.0   0.0   1.0  \n",
      "...    ...   ...   ...   ...  \n",
      "1678   1.0   1.0   0.0   0.0  \n",
      "1679   1.0   1.0   0.0   0.0  \n",
      "1680   1.0   1.0   0.0   0.0  \n",
      "1681   0.0   0.0   1.0   0.0  \n",
      "1682   0.0   0.0   0.0   1.0  \n",
      "\n",
      "[1681 rows x 1681 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your user_item_matrix: rows = movie_id, columns = user_id\n",
    "# Make sure your index is movie_id and columns are user_id\n",
    "movies = user_item_matrix.index.tolist()\n",
    "\n",
    "# Initialize empty DataFrame to store similarities\n",
    "similarity_matrix = pd.DataFrame(index=movies, columns=movies, dtype=float)\n",
    "\n",
    "for i, movie_i in enumerate(movies):\n",
    "    vec_i = user_item_matrix.loc[movie_i].values\n",
    "    for j, movie_j in enumerate(movies):\n",
    "        if j < i:\n",
    "            # Similarity matrix is symmetric, copy value\n",
    "            similarity_matrix.at[movie_i, movie_j] = similarity_matrix.at[movie_j, movie_i]\n",
    "        else:\n",
    "            vec_j = user_item_matrix.loc[movie_j].values\n",
    "            sim = cosine_similarity(vec_i, vec_j)\n",
    "            similarity_matrix.at[movie_i, movie_j] = sim\n",
    "\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ratings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll infer a missing rating of a user for an item by taking the normalized weighted sum of all the other ratings that user has given to different items. However, we will use only the top k most similar movies. The principle behind this is that the rating should be influenced primarily by the closest, most similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_id, user_item_matrix, similarity_matrix, k=5): \n",
    "    if movie_id not in user_item_matrix.index:\n",
    "        return np.nan\n",
    "\n",
    "    sims = similarity_matrix.loc[movie_id]\n",
    "    user_ratings = user_item_matrix[user_id]\n",
    "\n",
    "    # Drop target movie rating if exists\n",
    "    user_ratings = user_ratings.drop(movie_id, errors='ignore')\n",
    "\n",
    "    # Filter non-NaN pairs\n",
    "    mask = ~np.isnan(sims) & ~np.isnan(user_ratings)\n",
    "    sims = sims[mask]\n",
    "    user_ratings = user_ratings[mask]\n",
    "\n",
    "    # Select top-k most similar movies\n",
    "    top_k = sims.abs().sort_values(ascending=False).head(k)\n",
    "    user_ratings = user_ratings.loc[top_k.index]\n",
    "    sims = sims.loc[top_k.index]\n",
    "\n",
    "    numerator = np.sum(sims * user_ratings)\n",
    "    denominator = np.sum(np.abs(sims))\n",
    "\n",
    "    if denominator == 0:\n",
    "        # fallback: user mean or global mean (choose what fits your data)\n",
    "        return user_ratings.mean()\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.102745634508049"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rating(user_id=4, movie_id=1, user_item_matrix=user_item_matrix, similarity_matrix=similarity_matrix, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the top 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_N ( user_id, user_item_matrix, similarity_matrix, N=10, k=5):\n",
    "    if user_id not in user_item_matrix.columns:\n",
    "        return []\n",
    "\n",
    "    # Get all movies rated by the user\n",
    "    rated_movies = user_item_matrix[user_id].dropna().index.tolist()\n",
    "    \n",
    "    # Initialize a list to store predictions\n",
    "    predictions = []\n",
    "\n",
    "    for movie_id in user_item_matrix.index:\n",
    "        if movie_id not in rated_movies:\n",
    "            predicted_rating = predict_rating(user_id, movie_id, user_item_matrix, similarity_matrix, k)\n",
    "            if not np.isnan(predicted_rating):\n",
    "                predictions.append((movie_id, predicted_rating))\n",
    "\n",
    "    # Sort predictions by rating in descending order and take top N\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return  predictions[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " [(21, 5.000000000000001),\n",
       "  (49, 5.000000000000001),\n",
       "  (57, 5.000000000000001),\n",
       "  (84, 5.000000000000001),\n",
       "  (101, 5.000000000000001),\n",
       "  (106, 5.000000000000001),\n",
       "  (110, 5.000000000000001),\n",
       "  (169, 5.000000000000001),\n",
       "  (184, 5.000000000000001),\n",
       "  (198, 5.000000000000001)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_N( user_id=4, user_item_matrix=user_item_matrix, similarity_matrix=similarity_matrix, N=10, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Item-Item Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the transpose of the items_profile matrix, where each row represents a user based on their reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = user_item_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4         5         6         7    \\\n",
      "1    1.000000  0.957477  0.857075  0.898146  0.931616  0.953331  0.942811   \n",
      "2    0.957477  1.000000  0.935601  0.946544  0.979660  0.956301  0.963967   \n",
      "3    0.857075  0.935601  1.000000  0.919528  1.000000  0.890713  0.879543   \n",
      "4    0.898146  0.946544  0.919528  1.000000  1.000000  0.931108  0.855344   \n",
      "5    0.931616  0.979660  1.000000  1.000000  1.000000  0.933706  0.905738   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "939  0.944993  0.974901  0.993884  1.000000  0.930136  0.922565  0.957014   \n",
      "940  0.944952  0.944038  0.867865  0.961247  0.918769  0.949294  0.940097   \n",
      "941  0.972207  0.940225  0.973223  0.998538  0.975643  0.945658  0.937400   \n",
      "942  0.918030  0.948493  0.897758  0.977106  0.941836  0.960481  0.983202   \n",
      "943  0.929704  0.973154  0.989949  1.000000  0.908721  0.939325  0.930511   \n",
      "\n",
      "          8         9         10   ...       934       935       936  \\\n",
      "1    0.976932  0.976404  0.967975  ...  0.941967  0.871754  0.965889   \n",
      "2    0.958659  0.987805  0.980958  ...  0.947607  0.963031  0.966917   \n",
      "3    0.891056  1.000000  0.902444  ...  0.964901  1.000000  0.896328   \n",
      "4    0.970851  0.000000  0.937425  ...  0.970143  1.000000  0.944227   \n",
      "5    0.939518  0.880919  0.938785  ...  0.918808  0.917854  0.936373   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "939  0.989011  0.000000  0.993822  ...  0.963575  0.962738  0.979916   \n",
      "940  0.958734  0.980666  0.968278  ...  0.936097  0.951365  0.921295   \n",
      "941  0.931134  1.000000  0.986317  ...  0.943701  0.953817  0.974237   \n",
      "942  0.961113  0.992302  0.984505  ...  0.968616  0.948417  0.941054   \n",
      "943  0.947537  0.979800  0.966663  ...  0.938173  0.954926  0.943677   \n",
      "\n",
      "          937       938       939       940       941       942       943  \n",
      "1    0.918126  0.910709  0.944993  0.944952  0.972207  0.918030  0.929704  \n",
      "2    0.965690  0.941092  0.974901  0.944038  0.940225  0.948493  0.973154  \n",
      "3    0.840511  0.872572  0.993884  0.867865  0.973223  0.897758  0.989949  \n",
      "4    0.885438  0.947368  1.000000  0.961247  0.998538  0.977106  1.000000  \n",
      "5    0.965824  0.895525  0.930136  0.918769  0.975643  0.941836  0.908721  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "939  0.946969  0.939566  1.000000  0.991837  0.965729  0.980407  0.951989  \n",
      "940  0.858934  0.918300  0.991837  1.000000  0.960653  0.958008  0.963010  \n",
      "941  0.952969  0.932182  0.965729  0.960653  1.000000  0.982456  0.967762  \n",
      "942  0.994332  0.944244  0.980407  0.958008  0.982456  1.000000  0.975958  \n",
      "943  0.865335  0.942132  0.951989  0.963010  0.967762  0.975958  1.000000  \n",
      "\n",
      "[943 rows x 943 columns]\n"
     ]
    }
   ],
   "source": [
    "# user_item_matrix: rows = user_id, columns = user_id\n",
    "\n",
    "users = user_profile.index.tolist()\n",
    "\n",
    "# Initialize empty DataFrame to store similarities\n",
    "similarity_matrix_users = pd.DataFrame(index=users, columns=users, dtype=float)\n",
    "\n",
    "for i, user_i in enumerate(users):\n",
    "    vec_i = user_profile.loc[user_i].values\n",
    "    for j, user_j in enumerate(users):\n",
    "        if j < i:\n",
    "            # Similarity matrix is symmetric, copy value\n",
    "            similarity_matrix_users.at[user_i, user_j] = similarity_matrix_users.at[user_j, user_i]\n",
    "        else:\n",
    "            vec_j = user_profile.loc[user_j].values\n",
    "            sim = cosine_similarity(vec_i, vec_j)\n",
    "            similarity_matrix_users.at[user_i, user_j] = sim\n",
    "\n",
    "print(similarity_matrix_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict rating : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_user(user_id, movie_id, user_profile, similarity_matrix_users, k=5):\n",
    "    \"\"\"\n",
    "    Predict the rating of a user for a movie using user-based CF.\n",
    "    \"\"\"\n",
    "    if movie_id not in user_profile.columns:\n",
    "        return np.nan  # movie unknown\n",
    "\n",
    "    # Similarities of target user to all other users\n",
    "    sims = similarity_matrix_users.loc[user_id]\n",
    "\n",
    "    # Ratings of other users for the target movie\n",
    "    movie_ratings = user_profile[movie_id]\n",
    "\n",
    "    # Filter out users who haven't rated the movie\n",
    "    mask = movie_ratings.notna()\n",
    "    sims = sims[mask]\n",
    "    movie_ratings = movie_ratings[mask]\n",
    "\n",
    "    # Select top-k most similar users\n",
    "    top_k = sims.abs().sort_values(ascending=False).head(k)\n",
    "    movie_ratings = movie_ratings.loc[top_k.index]\n",
    "    sims = sims.loc[top_k.index]\n",
    "\n",
    "    # Weighted average\n",
    "    numerator = np.sum(sims * movie_ratings)\n",
    "    denominator = np.sum(np.abs(sims))\n",
    "\n",
    "    if denominator == 0:\n",
    "        # Fallback: return global mean rating of movie (or user mean)\n",
    "        return movie_ratings.mean()\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rating_user(4, 1, user_profile, similarity_matrix_users, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the top 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n_movies_user(user_id, user_profile, similarity_matrix_users, n=10, k=5):\n",
    "    \"\"\"\n",
    "    Recommend top-N movies to a user based on predicted ratings.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: target user\n",
    "    - user_profile: DataFrame with users as rows, movies as columns\n",
    "    - similarity_matrix_users: user-user similarity matrix\n",
    "    - n: number of movies to recommend\n",
    "    - k: number of neighbors to use in prediction\n",
    "    \n",
    "    Returns:\n",
    "    - List of (movie_id, predicted_rating), sorted by predicted_rating descending\n",
    "    \"\"\"\n",
    "    # Movies the user has already rated\n",
    "    user_ratings = user_profile.loc[user_id]\n",
    "    rated_movies = user_ratings[user_ratings.notna()].index.tolist()\n",
    "    \n",
    "    # Movies the user hasn't rated\n",
    "    unrated_movies = [movie for movie in user_profile.columns if movie not in rated_movies]\n",
    "    \n",
    "    predictions = []\n",
    "    for movie_id in unrated_movies:\n",
    "        pred_rating = predict_rating_user(user_id, movie_id, user_profile, similarity_matrix_users, k)\n",
    "        predictions.append((movie_id, pred_rating))\n",
    "    \n",
    "    # Sort movies by predicted rating descending\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N\n",
    "    return predictions[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(814, 5.000000000000001),\n",
       " (1293, 5.000000000000001),\n",
       " (1653, 5.000000000000001),\n",
       " (408, 5.0),\n",
       " (498, 5.0),\n",
       " (1122, 5.0),\n",
       " (1201, 5.0),\n",
       " (1467, 5.0),\n",
       " (1500, 5.0),\n",
       " (1599, 5.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_top_n_movies_user(4, user_profile, similarity_matrix_users, n=10, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Evaluating models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_ratings.pivot(index='movie_id', columns='user_id', values='rating')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach: We evaluate whether our system is able to assign a high rating to a movie (i.e., above its average rating) and a low rating to a movie (i.e., below its average rating).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.content based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1886\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mov_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m user_rating_for_movie\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m user_average_rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(ratings_df[ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m score_for_movie\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(\u001b[43mmov_matrix\u001b[49m[movie_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], user_matrix[user_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     12\u001b[0m all_scores_for_user\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(mov_matrix, user_matrix[user_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     13\u001b[0m average_score_for_user\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(all_scores_for_user)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mov_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "total_test_cases=len(test_ratings)\n",
    "hit=0\n",
    "print(total_test_cases)\n",
    "for index, row in test_ratings.iterrows():\n",
    "    user_id=row['user_id']\n",
    "    movie_id=row['movie_id']\n",
    "    movie=movies_df[movies_df['movie_id'] == movie_id].iloc[0]\n",
    "    movie_name=movie['title']\n",
    "    user_rating_for_movie=row['rating']\n",
    "    user_average_rating=round(ratings_df[ratings_df['user_id'] == user_id]['rating'].mean(),3)\n",
    "    score_for_movie=np.dot(mov_matrix[movie_id-1], user_matrix[user_id-1])\n",
    "    all_scores_for_user=np.dot(mov_matrix, user_matrix[user_id-1])\n",
    "    average_score_for_user=np.mean(all_scores_for_user)\n",
    "    user_has_rated=\"Below Average\"\n",
    "    score_has_been_given=\"Below Average\"\n",
    "    if user_rating_for_movie>(user_average_rating-user_average_rating*0.10):\n",
    "        user_has_rated=\"Above Average\"\n",
    "    if score_for_movie>(average_score_for_user-average_score_for_user*0.10):\n",
    "        score_has_been_given=\"Above Average\"\n",
    "    if user_has_rated==score_has_been_given:\n",
    "        hit=hit+1\n",
    "    # print(f\"user id : {user_id} \\n movie_name: {movie_name} \\n user has rated :{user_rating_for_movie} \\n user's average rating :{user_average_rating} \\n system score for movie :{score_for_movie} \\n average score for user :{average_score_for_user} \\n user_rated : {user_has_rated} \\n score_given : {score_has_been_given}\")\n",
    "average_accuracy=round((hit/total_test_cases)*100,2)\n",
    "print(f\"Average accuracy is : {average_accuracy} % \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Item_item approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ratings(test_set, user_item_matrix, similarity_matrix, k=5):\n",
    "    hits = 0\n",
    "    \n",
    "    for user_id in test_set.columns.unique():\n",
    "        rated_movies = test_set.index[test_set[user_id].notna()].tolist()\n",
    "        user_average_rating = remaining_df[remaining_df['user_id'] == user_id]['rating'].mean()\n",
    "        for movie_id in rated_movies:\n",
    "            predicted_rating = predict_rating(user_id, movie_id, user_item_matrix, similarity_matrix, k)\n",
    "            actual_rating = test_set.at[movie_id, user_id]\n",
    "            if not np.isnan(predicted_rating) and not np.isnan(actual_rating):\n",
    "                # Check if the predicted rating is above or below the user's average rating\n",
    "                user_has_rated = \"Above Average\" if actual_rating > (user_average_rating - user_average_rating * 0.10) else \"Below Average\"\n",
    "                score_has_been_given = \"Above Average\" if predicted_rating > (user_average_rating - user_average_rating * 0.10) else \"Below Average\"\n",
    "                \n",
    "                if user_has_rated == score_has_been_given:\n",
    "                    hits += 1\n",
    "\n",
    "    accuracy = (hits / (2*len(test_set.columns.unique()))) * 100 if len(test_set.columns.unique()) > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.87698833510075"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ratings(test_set, user_item_matrix, similarity_matrix, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- User_user approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ratings_user(test_set, user_profile, similarity_matrix_users, k=5):\n",
    "    hits = 0\n",
    "    \n",
    "    for user_id in test_set.columns.unique():\n",
    "        rated_movies = test_set.index[test_set[user_id].notna()].tolist()\n",
    "        user_average_rating = user_profile.loc[user_id].mean()\n",
    "        for movie_id in rated_movies:\n",
    "            predicted_rating = predict_rating_user(user_id, movie_id, user_profile, similarity_matrix_users, k)\n",
    "            actual_rating = test_set.at[movie_id, user_id]\n",
    "            if not np.isnan(predicted_rating) and not np.isnan(actual_rating):\n",
    "                # Check if the predicted rating is above or below the user's average rating\n",
    "                user_has_rated = \"Above Average\" if actual_rating > (user_average_rating - user_average_rating * 0.10) else \"Below Average\"\n",
    "                score_has_been_given = \"Above Average\" if predicted_rating > (user_average_rating - user_average_rating * 0.10) else \"Below Average\"\n",
    "                \n",
    "                if user_has_rated == score_has_been_given:\n",
    "                    hits += 1\n",
    "\n",
    "    accuracy = (hits / (2*len(test_set.columns.unique()))) * 100 if len(test_set.columns.unique()) > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.95227995758218"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ratings_user(test_set, user_profile, similarity_matrix_users, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach Evaluate whether the recommender system can suggest a movie that the user has interacted with, regardless of the rating (whether good or bad). This can be considered a good approach, because we assume that if a user has rated a movie, it means they were initially interested in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\ndef evaluate_recommendations(test_set):\\n    hits = 0\\n\\n    for user_id in test_set.columns.unique():\\n        recommendations = recommand_N(user_id, user_item_matrix, similarity_matrix)\\n\\n        # Convert recommendations to a set of movie IDs\\n        recommended_movie_ids = {movie_id for movie_id, _ in recommendations}\\n        \\n        # Get the actual ratings from the test set\\n        actual_ratings = test_ratings[test_ratings[\\'user_id\\'] == user_id][\\'movie_id\\'].values\\n        \\n        # Calculate hits (recommended movies that were actually rated)\\n        hit = len(set(recommended_movie_ids) & set(actual_ratings))\\n\\n        hits += hit\\n    hits = hits / len(test_set.columns.unique()) if len(test_set.columns.unique()) > 0 else 0    \\n    return hits\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "def evaluate_recommendations(test_set):\n",
    "    hits = 0\n",
    "\n",
    "    for user_id in test_set.columns.unique():\n",
    "        recommendations = recommend_N(user_id, user_item_matrix, similarity_matrix)\n",
    "\n",
    "        # Convert recommendations to a set of movie IDs\n",
    "        recommended_movie_ids = {movie_id for movie_id, _ in recommendations}\n",
    "        \n",
    "        # Get the actual ratings from the test set\n",
    "        actual_ratings = test_ratings[test_ratings['user_id'] == user_id]['movie_id'].values\n",
    "        \n",
    "        # Calculate hits (recommended movies that were actually rated)\n",
    "        hit = len(set(recommended_movie_ids) & set(actual_ratings))\n",
    "\n",
    "        hits += hit\n",
    "    hits = hits / len(test_set.columns.unique()) if len(test_set.columns.unique()) > 0 else 0    \n",
    "    return hits\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's taking more than 119 minutes to run this program, so let's use parallelism.\n",
    "The code below performs the same task as above, but it distributes the workload across multiple CPU cores to compute recommendations for all users.\n",
    "It splits the user IDs into batches, processes them in parallel, and then aggregates the results.\n",
    "This is made possible thanks to the joblib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def recommend_all(test_ratings,recommend_function, user_ids, **kwargs):\n",
    "    \"\"\"\n",
    "    Recommend movies for all users in parallel, using any recommender function.\n",
    "\n",
    "    Parameters:\n",
    "        recommend_function (function): A recommender function that takes at least a user_id as first argument.\n",
    "        user_ids (list): List of user IDs to generate recommendations for.\n",
    "        **kwargs: Any additional keyword arguments required by the recommender function.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary {user_id: list of recommendations}\n",
    "    \"\"\"\n",
    "    def wrapped_function(user_id):\n",
    "        return user_id, recommend_function(user_id, **kwargs)\n",
    "\n",
    "    # Run in parallel across user_ids\n",
    "    recommendations_all_users = Parallel(n_jobs=-1)(\n",
    "        delayed(wrapped_function)(user_id) for user_id in user_ids\n",
    "    )\n",
    "\n",
    "    # Convert result to a dictionary\n",
    "    recommendation_dict = dict(recommendations_all_users)\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the hit rate of recommendations by checking how many recommended items\n",
    "    were actually rated by the user in the test set.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "    \n",
    "    # Ensure test_ratings is a DataFrame with columns: user_id, movie_id\n",
    "    if not isinstance(test_ratings, pd.DataFrame):\n",
    "        raise ValueError(\"test_ratings must be a DataFrame with 'user_id' and 'movie_id' columns.\")\n",
    "    \n",
    "    for user_id, recommendations in recommendation_dict.items():\n",
    "        # Get recommended movie IDs\n",
    "        recommended_movie_ids = {movie_id for movie_id, _ in recommendations}\n",
    "\n",
    "        # Get movies the user has rated in the test set\n",
    "        actual_rated = test_ratings[test_ratings['user_id'] == user_id]['movie_id'].values\n",
    "\n",
    "        # Compute intersection (hits)\n",
    "        hit = len(set(recommended_movie_ids) & set(actual_rated))\n",
    "        hits += hit\n",
    "        total_users += 1\n",
    "\n",
    "    # Average hits per user\n",
    "    return (hits / total_users) if total_users > 0 else 0\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-content based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrecommend_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommend_top_n_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmov_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmovies_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m, in \u001b[0;36mrecommend_all\u001b[1;34m(test_ratings, recommend_function, user_ids, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_id, recommend_function(user_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Run in parallel across user_ids\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m recommendations_all_users \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_ids\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Convert result to a dictionary\u001b[39;00m\n\u001b[0;32m     26\u001b[0m recommendation_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(recommendations_all_users)\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "#recommend_all(test_ratings, recommend_top_n_content, user_ids=test_set.columns.unique(), mov_matrix=mov_matrix, user_matrix=user_matrix, movies_df=movies_df, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- item_item approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrecommend_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ratings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommend_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecommend_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_item_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_item_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 41\u001b[0m, in \u001b[0;36mrecommend_all\u001b[1;34m(test_ratings, recommend_function, user_ids, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_ratings must be a DataFrame with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id, recommendations \u001b[38;5;129;01min\u001b[39;00m recommendation_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Get recommended movie IDs\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     recommended_movie_ids \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Get movies the user has rated in the test set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     actual_rated \u001b[38;5;241m=\u001b[39m test_ratings[test_ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[1;32mIn[36], line 41\u001b[0m, in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_ratings must be a DataFrame with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id, recommendations \u001b[38;5;129;01min\u001b[39;00m recommendation_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Get recommended movie IDs\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     recommended_movie_ids \u001b[38;5;241m=\u001b[39m {movie_id \u001b[38;5;28;01mfor\u001b[39;00m movie_id, _ \u001b[38;5;129;01min\u001b[39;00m recommendations}\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Get movies the user has rated in the test set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     actual_rated \u001b[38;5;241m=\u001b[39m test_ratings[test_ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "recommend_all(test_ratings=test_ratings, recommend_function=recommend_N, user_ids=test_set.columns.unique(), user_item_matrix=user_item_matrix, similarity_matrix=similarity_matrix, N=10, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-  (User_user) approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_all(test_ratings=test_ratings, recommend_function=recommend_top_n_movies_user, user_ids=test_set.columns.unique(), user_profile=user_profile, similarity_matrix_users=similarity_matrix_users, n=10, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
